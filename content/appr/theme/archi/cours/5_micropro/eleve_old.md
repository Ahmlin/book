# 5. Microprocesseurs

TODO: partie introductive, images, vid√©os ...


<!-- Ce chapitre est compos√©e des sous-chapitres suivants:

```{tableofcontents}
```
 -->


A reprendre compl√®tement ...

## ALU et bascules

TODO

### ALU

TODO


### Bascules

TODO


### Conclusion

Dans ce sous-chapitre nous avons donc vu les briques de base des ordinateurs. √Ä savoir les √©l√©ments suivants:
* Les portes logiques qui s'assemblent en syst√®mes logiques qui effectuent des op√©rations logiques qui aboutissent √† des fonctions arithm√©tiques et logiques dans une ALU
* Les bascules qui permettent de m√©moriser une information et s'assemblent dans des registres

Nous pouvons les assembler dans des microprocesseurs que nous allons d√©tailler au sous-chapitre suivant.

::::{panels}
:column: col-lg-12 p-2
:card: bg-info

**Vite ... tr√®s vite**
^^^^
Nous avons d√©montr√© que finalement nos ordinateurs ont un cerveau tr√®s simple dans le fonctionnement de ses √©l√©ments de base: des portes logiques qui traitent des **0** ou des **1**. Il est cependant tr√®s difficile de se repr√©senter √† quel point ces traitements vont vite.
Imaginons pour cela que le processeur √©crive toutes les op√©rations qu'il effectue sur un ruban de papier et calculons la vitesse de d√©filement de ce papier. 

Pour cela nous faisons les hypoth√®ses suivantes:
* Les processeurs actuels ont une cadence d'horloge de 3GHz, c'est √† dire $3¬∑10^9 [s^{-1}]$. Pour simplifier nous allons supposer qu'ils effectuent une op√©ration par cycle[^1].
* Nous transcrivons un mot de 64 bit (taille standard pour les processeurs) sur une longueur de 15cm, ce qui correspond √† $15¬∑10^{-2}[m]$.

Le calcul devient alors:

$$
    3¬∑10^9 [s^{-1}] ¬∑ 15¬∑10^{-2}[m] \\
    45¬∑10^7 [m/s]
$$

Que nous convertissons en km:

$$
    45¬∑10^5 [km/s] ou encore: 450'000 [km/s]
$$

Rappelons que la vitesse de la lumi√®re est:

$$
    c \cong 300'000 [km/s]
$$

Ce qui veut dire que si un microprocesseur, tel que ceux que l'on trouve dans notre ordinateur ou notre smartphone, √©crivait sur un ruban de papier tout ce qu'il fait, ce ruban de papier devrait se d√©placer √† une fois et demi la vitesse de la lumi√®re. Ou encore, ce ruban ferait chaque seconde plus de 11 fois le tour de la terre.

Si les √©l√©ments de base sont simples, la complexit√© et la richesse des exp√©riences num√©riques comme l'immersion dans un jeu vid√©o proviennent de la quantit√© extraordinaire d'op√©rations effectu√©es.

[^1]: En fait le op√©rations d'un processeur prennent plus d'un cycle pour √™tre r√©alis√©es, mais comme les processeurs ont plusieurs c≈ìurs et un pipeline dont nous n'abordons pas ici le fonctionnement, la simplification propos√©e n'est pas aberrante.



::::

## De Turing √† Von Neumann

````{panels}

:img-top: media/JohnvonNeumann-LosAlamos.jpeg

John von Neumann
^^^^^
* **Naissance** 28 d√©cembre 1903 / Budapest 
* **D√©c√®s** 8 f√©vrier 1957 / Washington 
```{dropdown} Bio
:animate: fade-in-slide-down

John von Neumann est un math√©maticien et physicien am√©ricano-hongrois qui a apport√© des contributions importantes dans les domaines des math√©matiques, de la physique quantique, de l'informatique et de l'√©conomie. Il participa √† des projets militaires comme le projet Manhattan, sur la mise au point de la premi√®re bombe atomique am√©ricaine.
En informatique, on retient son nom pour l'√©laboration d'une architecture, publi√©e en 1945 et qui est encore aujourd'hui la r√©f√©rence dans la conception des ordinateurs. L'id√©e centrale de son architecture est de stocker dans la m√©moire √† la fois le programme et les donn√©es du programme. Sur ce dernier point, sa proposition est tr√®s similaire √† celle propos√©e par Turing.

```

----
:img-top: media/AlanTuring.jpeg

Alan Turing
^^^^^
* **Naissance** 23 juin 1912 Maida Vale (Londres) (Royaume-Uni) 
* **D√©c√®s** 	7 juin 1954 (√† 41 ans) Wilmslow (Cheshire) (Royaume-Uni) 
```{dropdown} Bio
:animate: fade-in-slide-down
Pendant la Seconde Guerre mondiale, [**Alan Mattison Turing**](https://fr.wikipedia.org/wiki/Alan_Turing Alan Turing) travaille pour les services secrets de l'arm√©e anglaise, en cryptographie. Il est charg√© de d√©chiffrer les messages allemands chiffr√©s avec la machine Enigma.
Dans un article de 1936, Alan Turing pr√©sente une ¬´machine √† programme enregistr√© dans laquelle le programme et les donn√©es ont une √©gale importance¬ª (G√©rard Berry).
```

````
### Contexte historique

````{panels}
:column: col-lg-12 p-2

**Contexte historique**
^^^^
L'ENIAC

````

````{panels}
:column: col-lg-12 p-2

**The Computers**

^^^^

Rapide historique des 6 femmes, premi√®res programmeuses et informaticiennes qui programm√®rent les premi√®res l'ENIAC

https://laughingsquid.com/eniac-project-female-computer-programmers/
https://www.youtube.com/channel/UCBCtLBE97EPz_Fk2FLxTX3Q
http://eniacprogrammers.org/see-the-film/



short bio + photo

----
````

## L'architecture de Von Neumann
L'id√©e centrale de l'architecture de von Neumann, √† l'instar de la machine de Turing, est d'enregistrer les donn√©es et le programme dans le m√™me espace m√©moire. Cela implique que le programme peut se modifier lui-m√™me comme s'il modifiait des donn√©es. L'intention derri√®re cette possibilit√© r√©sidait dans la capacit√© de modifier des adresses pour des branchements (sauts dans l'ex√©cution). Mais ce point ne sera finalement pas ou peu exploit√©. Par contre cela permet √† un programme de se crypter lui-m√™me au cours de son ex√©cution pour le rendre difficile √† identifier une fois charg√© en m√©moire ou, pire encore, pour √©chapper √† une d√©compilation pour en comprendre le fonctionnement. Cette derni√®re  particularit√© a √©t√© utilis√©e par des virus et des vers.

```{admonition} Anecdote
:class: Le ver Internet
Le 2 novembre 1988 est lanc√© le ver Morris ou ver de Morris ou  ver Internet ou encore Le Ver. Il est consid√©r√© comme le premier ver √† s'√™tre propag√© sur Internet et il a aussi men√© √† la premi√®re condamnation pour fraude informatique.
Robert Tappan Morris avait comme premi√®re intention de d√©montrer le principe de propagation et les vuln√©rabilit√©s, mais des erreur de programmation ont conduit √† une propagation hors de contr√¥le et √† un blocage de nombreux syst√®me. On consid√®re de mani√®re tr√®s approximative que dix pour cent des soixante mille machines connect√©es √† Internet avait √©t√© infect√©es √† l'√©poque.

```

```{figure} media/Von_Neumann_architecture_fr.svg 
---
height: 400px
width: 400px
name: architecture
---
Architecture de von Neumann.
```

On trouve dans le sch√©mas de la figure {numref}`architecture` les √©l√©ments suivants:

**L'ALU ou ULA, c'est-√†-dire l'unit√© logique et arithm√©tique**

Cette √©l√©ment est responsable d'effectuer les op√©rations logiques et arithm√©tiques.

**L'unit√© de contr√¥le**

Cette unit√© est responsable du s√©quen√ßage des op√©rations. C'est en quelque sorte le chef d'orchestre.

**La m√©moire**

La m√©moire contient le programme et les donn√©es.

**Les entr√©es et sorties**

Les entr√©es-sorties permettent de communiquer avec les autres p√©riph√©riques comme la souris, le clavier, l'√©cran, etc.


:::{admonition} Le mod√®le Turing
:class: note
Cette vid√©o de trente minutes pr√©sente le mod√®le Turing. On d√©couvre ainsi la vie et l'≈ìuvre d'Alan Turing ainsi que les r√©flexions qui ont abouti √† un mod√®le qui est encore aujourd'hui une r√©f√©rence dans le domaine de l'informatique, mais qui a aussi inspir√© de nombreux autres domaines scientifiques. On d√©couvre √©galement le contexte de la seconde guerre mondiale et le r√¥le crucial qu'a jou√© Turing dans la r√©solution de ce conflit.
```{cnrs} pUV9f15n
```
:::

:::{admonition} La machine de Turing r√©alis√©e
:class: note
Cette vid√©o de sept minutes pr√©sente une r√©alisation en lego de la machine de Turing. Les explications permettent d'en comprendre le fonctionnement.
```{cnrs} 0st7M134
```
:::

```{admonition} Activit√©
:class: note

[Simulateur de la machine de Turing](https://www.google.com/doodles/alan-turings-100th-birthday)

Ce simulateur permet de se familiariser avec le concept de programmation et de machine de Turing. Prenez quelques minutes (environ 10') pour r√©soudre les six enigmes propos√©es.

```



### R√©f√©rences

https://fr.wikipedia.org/wiki/John_von_Neumann
https://fr.wikipedia.org/wiki/John_von_Neumann#/media/Fichier:Von_Neumann_architecture_fr.svg



## Fonctionnement du microprocesseur

On se propose √† pr√©sent d'√©tudier le fonctionnement de base d'un processeur. On a pr√©c√©demment √©tudi√© le fonctionnement des syst√®mes logiques √† partir desquels on peut construire un processeur. L'architecture de von Neumann qui d√©crit la fa√ßon dont le processeur s'ins√®re dans son environnement qui constitue un ordinateur a √©t√© abord√©e. Les diff√©rents √©l√©ments qui constituent le processeur et qui en assurent le bon fonctionnement vont √† pr√©sent √™tre d√©taill√©s. 

````{panels}

:img-top: media/Gordon_Moore.jpeg

Gordon Moore
^^^^^
* **Naissance** 3 janvier 1929 / San Francisco üá∫üá∏ 
```{dropdown} Bio
:animate: fade-in-slide-down
Gordon Earle Moore est le cofondateur d'Intel en 1968. Intel est le premier fabricant mondial de microprocesseurs. Gordon Moore est c√©l√®bre pour avoir formul√© en 1965 une loi empirique portant son nom: **loi de Moore**. Cette loi pr√©dit un doublement de la complexit√©, et donc du nombre de transistors pr√©sents dans les microprocesseurs tous les deux ans. Bien que nous ayons atteint certaines limites physiques au niveau atomique et des effets de bruits parasites li√©s aux effets quantiques et √† la d√©sint√©gration alpha, la loi est toujours v√©rifi√©e aujourd'hui malgr√© un ralentissement de la progression pour certaines caract√©ristiques. Ces limites sont aujourd'hui compens√©es par des puces int√©grant de plus en plus de composants de plus en plus complexes.
```

````

```{admonition} (micro)-processeur
:class: attention
Le processeur est l'unit√© de traitement central de l'ordinateur. Il est construit avec des circuits regroup√©s en syst√®mes qui produisent des fonctions logiques et arithm√©tiques en suivant un programme et en utilisant des √©l√©ments de m√©moire appel√©s registres.
Un microprocesseur est un processeur construit avec un circuit int√©gr√©, c'est-√†-dire un dispositif qui tient sur quelques cm<sup>2</sup>. Il n'y a donc que la taille qui fasse la diff√©rence.

```


### L'horloge
Un processeur est un dispositif synchrone, ce qui signifie que les op√©rations √† l'int√©rieur du processeur se d√©roulent de mani√®re synchrone √† un temps donn√©. Pour assurer cette simultan√©it√©, il faut comme pour un orchestre, donner le tempo. Cette fonction de m√©tronome est assur√©e par une horloge, ou un signal d'horloge. Cette horloge est constitu√©e d'un simple signal carr√© <!-- TODO: ajouter image --> dont la fr√©quence atteint aujourd'hui plusieurs gigahertz, c'est-√†-dire plusieurs milliards de cycles par seconde.

```{admonition} La notion de *synchronisation*
:class: attention
La notion de synchronisation est centrale. 
Les syst√®mes num√©riques synchrones sont ceux dont les op√©rations (instructions, calculs, logique, etc.) sont coordonn√©es par un ou plusieurs signaux d'horloge centralis√©s, par opposition, aux syst√®mes asynchrones qui n'ont pas d'horloge globale. 
Les syst√®mes asynchrones ne d√©pendent pas d'heures d'arriv√©e strictes des signaux ou des messages pour un fonctionnement fiable. La coordination est obtenue via des tests sur l'arriv√©e des √©v√®nements.

Sans entrer dans les d√©tails ici, on notera que dans un syst√®me synchrone, il est possible d'assurer une coordination et une coh√©rence des op√©rations, ce qui est impossible autrement. Cet aspect devient crucial dans les syst√®mes distribu√©s qui ne disposent plus de la garantie de synchronisation.

Les circuits asynchrones ont √©t√© envisag√©s comme une alternative possible aux circuits synchrones, plus r√©pandus, particuli√®rement pour diminuer la consommation d'√©nergie, augmenter la vitesse, faciliter la conception et augmenter la fiabilit√©. Il semblerait qu'apr√®s avoir √©t√© un peu d√©laiss√©e par le monde de la recherche et du d√©veloppement depuis les ann√©es 1990 et 2000, la th√©matique des circuits asynchrones suscite √† nouveau un regain d'int√©r√™t, en particulier relativement aux imp√©ratifs de faible consommation √©nerg√©tique en relation avec le changement climatique.


```

### L'acc√®s √† la m√©moire

```{admonition} Rappel
:class: danger
Comme on l'a vu dans l'architecture de von Neumman, la m√©moire contient le programme et les donn√©es du programme. Un programme peut donc th√©oriquement se modifier lui-m√™me en se modifiant dans la m√©moire, m√™me si, en pratique, toutes les architectures modernes l'interdisent (c'est rarement un effet souhait√© !).
```

L'Unit√© Centrale de Traitement (UCT ou CPU en anglais pour Central Processing Unit) doit acc√©der √† la m√©moire. On parle de m√©moire RAM pour Random Access Memory. Le processeur peut acc√©der √† la m√©moire en lecture ou en √©criture. Les deux m√©canismes sont tr√®s similaires, mais avant de regarder plus en d√©tail comment cela fonctionne, il faut d'abord d√©finir comment la m√©moire est structur√©e. La m√©moire RAM permet, comme son nom l'indique, d'acc√©der √† tout moment √† n'importe quel emplacement.

Pour y acc√©der, le processeur envoie d'abord l'adresse au module m√©moire, puis lit ou √©crit la valeur. Pour cela le processeur dispose d'un **bus d'adressage**, appel√© encore bus d'adresses. Il s'agit physiquement de c√¢bles parall√®les qui relient le processeur √† la m√©moire. La taille de ce bus ou sa largeur d√©finissent le nombre de connexions parall√®les et d√©pendent des caract√©ristiques du processeur et de la RAM. Chaque connexion transporte un bit, un bus de largeur 32 bits transporte 32 bits, ce qui permet de r√©pertorier 2<sup>32</sup> adresses m√©moire diff√©rentes (env. 4 Go). Le bus de donn√©es, lui, transporte les donn√©es entre le processeur et la m√©moire (dans les deux sens). Ces deux bus, d'adressage et de donn√©es, ne sont pas forc√©ment de largeur identique.


La principale diff√©rence entre le bus d‚Äôadressage et le bus de donn√©es est que le bus d‚Äôadressage permet de transf√©rer des adresses de m√©moire, tandis que le bus de donn√©es facilite l‚Äôenvoi et la r√©ception de donn√©es. Le bus d'adressage est utilis√© pour sp√©cifier une adresse physique dans la m√©moire, tandis que le bus de donn√©es est utilis√© pour transmettre des donn√©es entre des composants dans les deux sens. Par cons√©quent, le bus d'adressage est unidirectionnel tandis que le bus de donn√©es est bidirectionnel.

```{figure} media/Im58.gif
---
alt: bus de donn√©es
width: 750px
---
Bus de donn√©es et d'adresses - communication avec le CPU, les m√©moires ROM et RAM et les entr√©es-sorties.
```



 ```{admonition} Anecdote
:class: attention
Le processeur Intel 80286 (anc√™tre des processeurs Pentium), sorti en 1982, pr√©sentait un bus de donn√©es de 16 bits et un bus d'adresses de 24 bits. De plus l'adressage par segments (relativement compliqu√©) r√©duisait l'adressage physique √† un adressage sur 20 bits.
```

 Il manque encore un √©l√©ment: lorsque la m√©moire voit une adresse appara√Ætre elle doit pouvoir d√©terminer s'il s'agit d'une lecture ou d'une √©criture. Pour cela deux connexions suppl√©mentaires relient le processeur √† la m√©moire: une ligne *enable* et une ligne *set*. Lorsque la ligne *enable* est √† 1, alors le processeur acc√®de √† la m√©moire en lecture et sur le bus de donn√©es doit appara√Ætre les donn√©es qui sont stock√©es dans la m√©moire √† l'adresse indiqu√©e sur le bus d'adressage. Lorsque c'est la ligne *set* qui est √† 1, alors la m√©moire doit enregistrer les donn√©es √† l'adresse indiqu√©e.

```{admonition} Le contenu de la m√©moire
:class: hint

**Les instructions**: 
la m√©moire contient le programme sous forme de codes qui repr√©sentent des instructions √† ex√©cuter par le processeur. Ces codes correspondent √† un jeu d'instructions propre √† chaque mod√®le de processeur. On parle de langage machine. Pour √©crire de tels programmes, on utilise un programme et un langage assembleur, proche de la machine: c'est une repr√©sentation exacte du langage machine, mais qui est une interface plus lisible dans la communication machine. C'est le langage de plus bas niveau qui repr√©sente le langage machine sous une forme lisible par un humain.


**Les donn√©es**: 
les donn√©es stock√©es dans la m√©moire peuvent √™tre des nombres, des lettres, des cha√Ænes de caract√®res ainsi que des adresses d'autres emplacements en m√©moire. On trouvera plus de d√©tails √† ce sujet dans le chapitre [*Repr√©sentation de l'information*](/content/appr/theme/rep-info/accueil/eleve.md "Repr√©sentation de l'information").

```


```{question} Question 1
Avec un bus d'adressage de 24 bits, quelle est la taille maximum de la m√©moire ? 
* {f}`32ko`
* {v}`16Mo`
* {f}`16Go`
```

```{question} Question 2
Quelle est la taille maximale de la m√©moire pour un processeur 80286, sachant que l'adressage physique est finalement r√©duit √† 20 bits ? 
* {f}`32ko`
* {f}`16Mo`
* {v}`1Mo`
```


### L'unit√© de contr√¥le
L'unit√© de contr√¥le re√ßoit les instructions en provenance de la RAM. Elle s'occupe d'activer les composants qui doivent l'√™tre dans le microprocesseur.

### Les registres
Les registres permettent de stocker des valeurs, comme la RAM, mais directement √† l'int√©rieur du processeur. Ils fonctionnent aussi en mode lecture ou √©criture. C'est l'unit√© de contr√¥le qui d√©termine si un registre est utilis√© en lecture ou en √©criture avec deux fils de connexion: *enable* et *set*.
En principe ces registres stockent les informations en provenance de la m√©moire ou le r√©sultat d'un calcul.
Il existe trois registres plus sp√©cifiques:

#### <u> Le registre d'√©tat </u>
Le registre d'√©tat regroupe les drapeaux (en anglais *flags*). Ils servent √† renseigner l'√©tat d'ex√©cution du processeur. Par exemple le drapeau *d√©passement* s'il est mis √† 1 signale qu'un d√©passement de capacit√© est survenu, ou encore le drapeau *division par z√©ro* signale une division par z√©ro.

### Le compteur de programme
Le compteur de programme (registre **PC** pour *Program Counter*) contient l'adresse m√©moire de la prochaine instruction devant √™tre ex√©cut√©e. En principe l'unit√© de contr√¥le l'incr√©mente de un apr√®s chaque instruction, mais certaines instructions qui permettent de se *brancher* ailleurs dans le programme modifient diff√©remment ce registre.

### Le compteur de pile
Le compteur de pile (registre **SP** pour *Stack Pointer*) contient la position sur une pile. Cette derni√®re est une zone m√©moire √† laquelle on ne peut pas acc√©der al√©atoirement, mais uniquement en empilant ou d√©pilant des √©l√©ments.

### L'unit√© arithm√©tique et logique
L'unit√© arithm√©tique et logique (UAL plus commun√©ment appel√©e ALU en abr√©viation anglaise) effectue tous les calculs arithm√©tiques et logiques. Quelques-uns de ces composants comme l'additionneur ont √©t√© abord√©s dans le chapitre *Syst√®mes logiques*.


#### <u> Exemple: le 6502 </u>

Le 6502, con√ßu en 1975, est le premier microprocesseur grand public avec un prix de 25$ (bien en-dessous des concurrents de cette √©poque). Une de ses premi√®res utilisations pour le grand public fut la console de jeux vid√©o Atari 2600. A partir de 1985, Nintendo √©quipe la NES d'une version modifi√©e du 6502. Il a √©quip√© √©galement le c√©l√®bre Apple II. Il a donn√© lieu √† de nombreuses versions, jusqu'aux processeurs 16 bits actuels de derni√®re g√©n√©ration.

```{figure} media/6502_pad_annot_07.png
---
alt: sch√©mas annot√© du 6502
width: 750px
---
Ce sch√©ma d√©taille l'ensemble des transistors du 6502. On voit √©galement quelques-uns des √©l√©ments principaux (horloge, registres, etc).
```

```{admonition} Activit√©
:class: note

[Simulateur visuel du 6502](http://visual6502.org/JSSim/index.html)

Ce simulateur reproduit le fonctionnement complet du 6502 jusque dans l'activit√© de chaque transistor. On peut clairement visualiser la fa√ßon dont la complexit√© du fonctionnement de ce qu'on appelle commun√©ment le *cerveau* de l'ordinateur √©merge de la quantit√© de dispositifs triviaux pris individuellement.

1. Observer le d√©roulement du programme propos√© et tenter d'en d√©duire le fonctionnement. On pourra s'aider du d√©sassembleur propos√© sur la m√™me page.
    :::{question} Question
    Que fait le programme en exemple sur le site visual6502 ?
    {f}`Il parcourt la m√©moire et recopie la valeur 40 √† des adresses successives.`
    {v}`Il effectue une boucle et incr√©mente une valeur en m√©moire √† l'adresse FF.`
    {f}`Il additionne deux registres et stocke le r√©sultat dans un autre registre.`
    :::
<br> 2. Modifier ou √©crire un nouveau programme en allant sur la page *Avanced*.

<!-- REVIEW/Olivier: Alors l√†, s√©rieusement, c'est super-difficile √† voir ce qui se passe... Un peu en effet ! Mais bon.../CD -->

```
## Pour aller plus loin

Les microprocesseurs modernes ajoutent quelques √©l√©ments de complexit√© qui n'ont pas √©t√© expos√©s ici. Il s'agit notamment des √©l√©ments suivants.

### Les processeurs multi-c≈ìurs

Alors que dans les processeurs jusqu'ici √©voqu√©s, il n'y avait qu'une seule unit√© arithm√©tique et logique, ce qui limitait le processeur √† une op√©ration par cycle d'horloge, l'industrie fournit aujourd'hui des microprocesseurs qui sont capables d'effectuer plusieurs op√©rations simultan√©ment. Pour cela, ces derniers sont dot√©s de plusieurs c≈ìurs capables d'effectuer chacun une op√©ration. Si cette mise en parall√®le des op√©rations ne se fait pas sans difficult√©s, elle offre toutefois la possibilit√© de palier en particulier aux probl√®mes d'√©l√©vation de temp√©rature dues √† l'augmentation de la fr√©quence, pour des sollicitations importantes de processeurs monoc≈ìurs (c'est √† dire des calculs lourds), en r√©duisant sensiblement la consommation √©nerg√©tique, param√®tre particuli√®rement d'importance aujourd'hui.



### Le pipeline

On l'a vu, l'ex√©cution d'une instruction par le microprocesseur implique plusieurs op√©rations: acc√®s √† la m√©moire en lecture et en √©criture, acc√®s aux registres en lecture et en √©criture, op√©ration logique. Pour optimiser la vitesse d'ex√©cution, les processeurs modernes effectuent en s√©rie ces op√©rations. Ainsi, alors que les op√©rations logiques d'une instruction sont effectu√©es, l'instruction pr√©c√©dente est d√©j√† charg√©e en m√©moire. La difficult√© de ce type d'optimisation r√©side dans le fait que des branchements conditionnels provoquent l'annulation des instructions d√©j√† charg√©es. Pour optimiser encore ce genre de proc√©d√©, les processeurs font de la pr√©diction dans l'ex√©cution. Ces optimisations sont extr√™mement compliqu√©es √† g√©rer.

 ```{admonition} Anecdote
:class: attention
La vuln√©rabilit√© Spectre (ainsi que d'autres vuln√©rabilit√©s similaires) exploite justement cette fonction de pr√©diction dans l'ex√©cution de branchements conditionnels pour acc√©der √† des emplacements m√©moire auxquels le programme ne devrait en principe pas acc√©der.
```
